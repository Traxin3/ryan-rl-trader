algorithm: impala

# Model/Transformer hyperparameters
model:
  features_dim: 256
  transformer:
    d_model: 256
    nhead: 8
    num_layers: 4
    dropout: 0.1

# Environment Configuration
env:
  symbols: ["EURUSD"]
  timeframes: [15]
  window_size: 100
  reward_scaling: 2.0
  min_reward: -10.0
  max_reward: 10.0
  survival_bonus: 0.02
  leverage_penalty: 0.02
  trade_reward_multiplier: 2.0
  drawdown_penalty: 0.2
  early_close_bonus: 0.1
  volatility_penalty: 0.05
  position_size_penalty: 0.02
  max_leverage: 20.0
  min_tp_sl_ratio: 1.8
  atr_multiplier: 2.2
  use_cached_features: true
  execution_cost_penalty_weight: 0.1
  max_daily_drawdown: 0.2

# IMPALA training hyperparameters
impala:
  learning_rate: 0.0005
  # Rollout scaling for heavy envs
  num_rollout_workers: 4           # increase with CPU cores
  num_envs_per_worker: 2           # vectorize envs per worker
  rollout_fragment_length: 200     # longer fragments amortize overhead
  num_aggregation_workers: 1       # offload batch collation
  # Batching
  batch_size: 8192                 # learner batch size
  minibatch_size: 1024             # per-epoch minibatch
  learner_queue_size: 32
  # Compression for large observations
  compress_observations: true
  # GPU
  num_gpus: 1
  # Reporting cadence
  min_time_s_per_iteration: 10

# Global stop criteria (overrides iteration-based)
stop:
  timesteps_total: 2000000